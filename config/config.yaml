# Spark Cluster Configuration
spark:
  version: "3.5.0"
  master:
    memory: "2g"
    cores: "2"
  worker:
    memory: "2g"
    cores: "2"
    instances: 1
  executor:
    memory: "1g"
    cores: "1"

# Python Package Configuration
python:
  version: "3.11"
  packages:
    # Data Science Core
    - "pandas>=2.0.0"
    - "numpy>=1.24.0"
    - "scipy>=1.10.0"
    
    # Machine Learning
    - "scikit-learn>=1.3.0"
    - "xgboost>=1.7.0"
    
    # Visualization
    - "matplotlib>=3.7.0"
    - "seaborn>=0.12.0"
    - "plotly>=5.15.0"
    
    # Spark Integration
    - "findspark>=2.0.0"
    - "pyspark[sql]==3.5.0"
    
    # Development Tools
    - "jupyter>=1.0.0"
    - "ipykernel>=6.25.0"
    - "notebook>=7.0.0"
    
    # Data Processing
    - "pyarrow>=12.0.0"
    - "openpyxl>=3.1.0"
    
    # Optional: Add your custom packages here
    # - "your-package>=1.0.0"

# Container Configuration
containers:
  jupyter:
    port: 8888
    token: ""
    password: ""
  
  spark_master:
    ui_port: 8080
    port: 7077
  
  spark_worker:
    ui_port: 8081

# Volume Configuration  
volumes:
  notebooks_path: "./notebooks"
  data_path: "./data"
  
# Network Configuration
network:
  name: "spark-network" 